{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d3a4214",
      "metadata": {
        "id": "8d3a4214"
      },
      "source": [
        "# Download a FineTuned Model \n",
        "This notebook demonstrates how to download a finetuned model that you've created using LLM Engine and add it to huggingface!\n",
        "\n",
        "**This notebook is an extension of the previous finetuning notebook on ScienceQA**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XK6VpTnOL4OV",
      "metadata": {
        "id": "XK6VpTnOL4OV"
      },
      "source": [
        "# Packages Required\n",
        "For this demo, we'll be using the `scale-llm-engine` package, the `datasets` package for downloading our finetuning dataset, `transformers`, and `huggingface_hub` for uploading our model to huggingface.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "S5u6DdInMEQ7",
      "metadata": {
        "id": "S5u6DdInMEQ7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scale-llm-engine\n",
            "  Downloading scale_llm_engine-0.0.0b28-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting aiohttp<4.0,>=3.8 (from scale-llm-engine)\n",
            "  Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl.metadata (7.6 kB)\n",
            "Collecting pydantic>=1.10 (from scale-llm-engine)\n",
            "  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
            "     ---------------------------------------- 0.0/85.1 kB ? eta -:--:--\n",
            "     ---------------------------------------- 85.1/85.1 kB 2.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from scale-llm-engine) (2.31.0)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0,>=3.8->scale-llm-engine)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from aiohttp<4.0,>=3.8->scale-llm-engine) (23.1.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0,>=3.8->scale-llm-engine)\n",
            "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0,>=3.8->scale-llm-engine)\n",
            "  Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl.metadata (4.3 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0,>=3.8->scale-llm-engine)\n",
            "  Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl.metadata (32 kB)\n",
            "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0,>=3.8->scale-llm-engine)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=1.10->scale-llm-engine)\n",
            "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic-core==2.16.3 (from pydantic>=1.10->scale-llm-engine)\n",
            "  Downloading pydantic_core-2.16.3-cp39-none-win_amd64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from pydantic>=1.10->scale-llm-engine) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests<3.0.0,>=2.31.0->scale-llm-engine) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests<3.0.0,>=2.31.0->scale-llm-engine) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests<3.0.0,>=2.31.0->scale-llm-engine) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests<3.0.0,>=2.31.0->scale-llm-engine) (2023.11.17)\n",
            "Downloading scale_llm_engine-0.0.0b28-py3-none-any.whl (26 kB)\n",
            "Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl (366 kB)\n",
            "   ---------------------------------------- 0.0/366.0 kB ? eta -:--:--\n",
            "   ---------------------- ----------------- 204.8/366.0 kB 4.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 366.0/366.0 kB 4.6 MB/s eta 0:00:00\n",
            "Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
            "   ---------------------------------------- 0.0/394.9 kB ? eta -:--:--\n",
            "   -------------------------- ------------- 266.2/394.9 kB 5.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 394.9/394.9 kB 6.2 MB/s eta 0:00:00\n",
            "Downloading pydantic_core-2.16.3-cp39-none-win_amd64.whl (1.9 MB)\n",
            "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 0.3/1.9 MB 7.9 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 0.7/1.9 MB 7.1 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.1/1.9 MB 7.5 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.4/1.9 MB 7.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 1.7/1.9 MB 7.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.9/1.9 MB 7.0 MB/s eta 0:00:00\n",
            "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
            "   ---------------------------------------- 0.0/50.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 50.7/50.7 kB 2.5 MB/s eta 0:00:00\n",
            "Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
            "Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
            "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 76.9/76.9 kB 4.2 MB/s eta 0:00:00\n",
            "Installing collected packages: pydantic-core, multidict, frozenlist, async-timeout, annotated-types, yarl, pydantic, aiosignal, aiohttp, scale-llm-engine\n",
            "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 frozenlist-1.4.1 multidict-6.0.5 pydantic-2.6.4 pydantic-core-2.16.3 scale-llm-engine-0.0.0b28 yarl-1.9.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (4.39.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from datasets) (1.24.4)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.2-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Downloading pandas-2.2.1-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from datasets) (0.22.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: colorama in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\namit\\appdata\\local\\pypoetry\\cache\\virtualenvs\\openfabric-test-ugfvbds8-py3.9\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "   ---------------------------------------- 0.0/510.5 kB ? eta -:--:--\n",
            "   -------------------- ------------------- 256.0/510.5 kB 7.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 510.5/510.5 kB 5.3 MB/s eta 0:00:00\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 116.3/116.3 kB 6.6 MB/s eta 0:00:00\n",
            "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "   ---------------------------------------- 0.0/170.9 kB ? eta -:--:--\n",
            "   --------------------------------------- 170.9/170.9 kB 10.0 MB/s eta 0:00:00\n",
            "Downloading pyarrow-15.0.2-cp39-cp39-win_amd64.whl (24.9 MB)\n",
            "   ---------------------------------------- 0.0/24.9 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.2/24.9 MB 9.0 MB/s eta 0:00:03\n",
            "   ---------------------------------------- 0.2/24.9 MB 9.0 MB/s eta 0:00:03\n",
            "   ---------------------------------------- 0.2/24.9 MB 9.0 MB/s eta 0:00:03\n",
            "    --------------------------------------- 0.4/24.9 MB 1.9 MB/s eta 0:00:13\n",
            "    --------------------------------------- 0.5/24.9 MB 2.2 MB/s eta 0:00:12\n",
            "   - -------------------------------------- 0.8/24.9 MB 3.0 MB/s eta 0:00:09\n",
            "   - -------------------------------------- 1.2/24.9 MB 3.7 MB/s eta 0:00:07\n",
            "   -- ------------------------------------- 1.5/24.9 MB 4.0 MB/s eta 0:00:06\n",
            "   -- ------------------------------------- 1.7/24.9 MB 4.0 MB/s eta 0:00:06\n",
            "   --- ------------------------------------ 2.0/24.9 MB 4.1 MB/s eta 0:00:06\n",
            "   --- ------------------------------------ 2.3/24.9 MB 4.3 MB/s eta 0:00:06\n",
            "   ---- ----------------------------------- 2.7/24.9 MB 4.6 MB/s eta 0:00:05\n",
            "   ---- ----------------------------------- 3.0/24.9 MB 4.8 MB/s eta 0:00:05\n",
            "   ----- ---------------------------------- 3.4/24.9 MB 5.1 MB/s eta 0:00:05\n",
            "   ------ --------------------------------- 3.8/24.9 MB 5.3 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 4.2/24.9 MB 5.6 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 4.6/24.9 MB 5.6 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 4.9/24.9 MB 5.7 MB/s eta 0:00:04\n",
            "   -------- ------------------------------- 5.1/24.9 MB 5.7 MB/s eta 0:00:04\n",
            "   -------- ------------------------------- 5.5/24.9 MB 5.8 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 5.8/24.9 MB 5.9 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 6.0/24.9 MB 5.8 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 6.4/24.9 MB 5.9 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 6.7/24.9 MB 6.0 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 7.2/24.9 MB 6.1 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 7.7/24.9 MB 6.2 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 8.0/24.9 MB 6.3 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 8.4/24.9 MB 6.3 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 8.8/24.9 MB 6.4 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 9.2/24.9 MB 6.5 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 9.5/24.9 MB 6.5 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 9.9/24.9 MB 6.5 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 10.3/24.9 MB 6.6 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 10.8/24.9 MB 7.5 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 11.2/24.9 MB 7.5 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 11.6/24.9 MB 7.6 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 11.9/24.9 MB 7.8 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 12.3/24.9 MB 7.9 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 12.6/24.9 MB 7.9 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 13.1/24.9 MB 7.9 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 13.4/24.9 MB 8.0 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 14.0/24.9 MB 8.0 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 14.5/24.9 MB 8.0 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 14.8/24.9 MB 8.0 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 15.2/24.9 MB 8.2 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 15.5/24.9 MB 8.1 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 15.9/24.9 MB 8.3 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 16.2/24.9 MB 8.2 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 16.5/24.9 MB 8.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 17.0/24.9 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 17.4/24.9 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 17.9/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 18.3/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 18.7/24.9 MB 8.3 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 19.1/24.9 MB 8.3 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 19.4/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 19.8/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 20.2/24.9 MB 8.3 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 20.6/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 21.0/24.9 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 21.5/24.9 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 21.7/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 22.1/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 22.5/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 22.8/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 23.3/24.9 MB 8.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 23.7/24.9 MB 8.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 24.0/24.9 MB 8.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.3/24.9 MB 8.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.9/24.9 MB 8.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 24.9/24.9 MB 7.9 MB/s eta 0:00:00\n",
            "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
            "   ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 133.4/133.4 kB 7.7 MB/s eta 0:00:00\n",
            "Downloading pandas-2.2.1-cp39-cp39-win_amd64.whl (11.6 MB)\n",
            "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.2/11.6 MB 5.9 MB/s eta 0:00:02\n",
            "   - -------------------------------------- 0.5/11.6 MB 5.5 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 0.9/11.6 MB 6.6 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 1.2/11.6 MB 7.2 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 1.5/11.6 MB 6.9 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 2.1/11.6 MB 7.3 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 2.5/11.6 MB 7.4 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 2.9/11.6 MB 7.5 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 3.3/11.6 MB 7.5 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 3.7/11.6 MB 7.6 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 4.0/11.6 MB 7.6 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 4.4/11.6 MB 7.7 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 4.8/11.6 MB 7.9 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 5.2/11.6 MB 7.9 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 5.5/11.6 MB 7.9 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 6.0/11.6 MB 7.9 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 6.4/11.6 MB 7.7 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 6.9/11.6 MB 7.8 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 7.2/11.6 MB 7.8 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 7.7/11.6 MB 7.9 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 8.1/11.6 MB 8.0 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 8.5/11.6 MB 8.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 8.9/11.6 MB 8.0 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 9.3/11.6 MB 8.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.5/11.6 MB 7.9 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 10.1/11.6 MB 8.0 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.6/11.6 MB 8.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 11.0/11.6 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.4/11.6 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.6/11.6 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.6/11.6 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.6/11.6 MB 7.9 MB/s eta 0:00:00\n",
            "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl (29 kB)\n",
            "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 345.4/345.4 kB 7.3 MB/s eta 0:00:00\n",
            "Installing collected packages: xxhash, tzdata, pyarrow-hotfix, pyarrow, fsspec, dill, pandas, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.3.1\n",
            "    Uninstalling fsspec-2024.3.1:\n",
            "      Successfully uninstalled fsspec-2024.3.1\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 fsspec-2024.2.0 multiprocess-0.70.16 pandas-2.2.1 pyarrow-15.0.2 pyarrow-hotfix-0.6 tzdata-2024.1 xxhash-3.4.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install scale-llm-engine\n",
        "%pip install transformers\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3dc2a56",
      "metadata": {
        "id": "a3dc2a56"
      },
      "source": [
        "# Data Preparation\n",
        "Let's load in the dataset using Huggingface and view the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1353b8df",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting smart_open\n",
            "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting wrapt (from smart_open)\n",
            "  Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
            "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
            "   ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
            "   ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
            "   ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
            "   ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
            "   -------------------------- ------------- 41.0/61.2 kB 196.9 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 61.2/61.2 kB 272.6 kB/s eta 0:00:00\n",
            "Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl (37 kB)\n",
            "Installing collected packages: wrapt, smart_open\n",
            "Successfully installed smart_open-7.0.4 wrapt-1.16.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install smart_open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e06ac39e",
      "metadata": {
        "id": "e06ac39e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading readme: 100%|██████████| 2.19k/2.19k [00:00<?, ?B/s]\n",
            "Downloading data: 100%|██████████| 39.8M/39.8M [00:13<00:00, 2.90MB/s]\n",
            "Generating train split: 50000 examples [10:19, 80.77 examples/s] \n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from smart_open import smart_open\n",
        "import pandas as pd\n",
        "\n",
        "physics_dataset = load_dataset('camel-ai/physics')\n",
        "chemistry_dataset = load_dataset('camel-ai/chemistry')\n",
        "biology_dataset = load_dataset('camel-ai/biology')\n",
        "maths_dataset = load_dataset('camel-ai/math')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "430dbac6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_prompt(r):\n",
        "    return r['message_1']\n",
        "\n",
        "def format_label(r):\n",
        "    return r['message_2']\n",
        "\n",
        "def convert_dataset(ds):\n",
        "    prompts = [format_prompt(i) for i in ds]\n",
        "    labels = [format_label(i) for i in ds]\n",
        "    df = pd.DataFrame.from_dict({'prompt': prompts, 'response': labels})\n",
        "    return df\n",
        "\n",
        "physics_train_data = convert_dataset(physics_dataset['train'])\n",
        "maths_train_data = convert_dataset(maths_dataset['train'])\n",
        "chemistry_train_data = convert_dataset(chemistry_dataset['train'])\n",
        "biology_train_data = convert_dataset(biology_dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8a8d8e6e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the probability of finding a particle ...</td>\n",
              "      <td>To find the probability of finding a particle ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the time-independent Schrödinger equat...</td>\n",
              "      <td>The time-independent Schrödinger equation is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Determine the wave function and energy eigenva...</td>\n",
              "      <td>To determine the wave function and energy eige...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the possible energy levels and wave f...</td>\n",
              "      <td>To solve this problem, we need to apply the ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If a particle is located in a one-dimensional ...</td>\n",
              "      <td>Yes, I can help you find the possible energy l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>What are the current conservation efforts and ...</td>\n",
              "      <td>Current conservation efforts and methods being...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>What are the current strategies being used for...</td>\n",
              "      <td>The conservation and preservation of endangere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>How can we effectively preserve and conserve e...</td>\n",
              "      <td>To effectively preserve and conserve endangere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>How can the preservation of endangered fungal ...</td>\n",
              "      <td>The preservation of endangered fungal species ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>How can we develop effective preservation stra...</td>\n",
              "      <td>Developing effective preservation strategies f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>110000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  prompt  \\\n",
              "0      What is the probability of finding a particle ...   \n",
              "1      What is the time-independent Schrödinger equat...   \n",
              "2      Determine the wave function and energy eigenva...   \n",
              "3      What are the possible energy levels and wave f...   \n",
              "4      If a particle is located in a one-dimensional ...   \n",
              "...                                                  ...   \n",
              "19995  What are the current conservation efforts and ...   \n",
              "19996  What are the current strategies being used for...   \n",
              "19997  How can we effectively preserve and conserve e...   \n",
              "19998  How can the preservation of endangered fungal ...   \n",
              "19999  How can we develop effective preservation stra...   \n",
              "\n",
              "                                                response  \n",
              "0      To find the probability of finding a particle ...  \n",
              "1      The time-independent Schrödinger equation is a...  \n",
              "2      To determine the wave function and energy eige...  \n",
              "3      To solve this problem, we need to apply the ti...  \n",
              "4      Yes, I can help you find the possible energy l...  \n",
              "...                                                  ...  \n",
              "19995  Current conservation efforts and methods being...  \n",
              "19996  The conservation and preservation of endangere...  \n",
              "19997  To effectively preserve and conserve endangere...  \n",
              "19998  The preservation of endangered fungal species ...  \n",
              "19999  Developing effective preservation strategies f...  \n",
              "\n",
              "[110000 rows x 2 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.concat([physics_train_data, chemistry_train_data, maths_train_data, biology_train_data])\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d5564ca6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\namit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\openfabric-test-UGfvBDS8-py3.9\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "train, validate = np.split(df_train.sample(frac=1, random_state=42), [int(.8 * len(df_train))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "0ffc0fc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "train.to_csv('train.csv', index=False)  \n",
        "validate.to_csv('val.csv', index=False)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cbe8a58",
      "metadata": {
        "id": "1cbe8a58"
      },
      "source": [
        "Now, let's format the dataset into what's acceptable for LLM Engine - a CSV file with 'prompt' and 'response' columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0eb8ad",
      "metadata": {
        "id": "0b0eb8ad"
      },
      "outputs": [],
      "source": [
        "choice_prefixes = [chr(ord('A') + i) for i in range(26)] # A-Z\n",
        "def format_options(options, choice_prefixes):\n",
        "    return ' '.join([f'({c}) {o}' for c, o in zip(choice_prefixes, options)])\n",
        "\n",
        "def format_prompt(r, choice_prefixes):\n",
        "    options = format_options(r['choices'], choice_prefixes)\n",
        "    return f'''Context: {r[\"hint\"]}\\nQuestion: {r[\"question\"]}\\nOptions:{options}\\nAnswer:'''\n",
        "\n",
        "def format_label(r, choice_prefixes):\n",
        "    return choice_prefixes[r['answer']]\n",
        "\n",
        "def convert_dataset(ds):\n",
        "    prompts = [format_prompt(i, choice_prefixes) for i in ds if i['hint'] != '']\n",
        "    labels = [format_label(i, choice_prefixes) for i in ds if i['hint'] != '']\n",
        "    df = pd.DataFrame.from_dict({'prompt': prompts, 'response': labels})\n",
        "    return df\n",
        "\n",
        "save_to_s3 = False\n",
        "df_train = convert_dataset(dataset['train'])\n",
        "if save_to_s3:\n",
        "    train_url = 's3://...'\n",
        "    val_url = 's3://...'\n",
        "    df_train = convert_dataset(dataset['train'])\n",
        "    with smart_open(train_url, 'wb') as f:\n",
        "        df_train.to_csv(f)\n",
        "\n",
        "    df_val = convert_dataset(dataset['validation'])\n",
        "    with smart_open(val_url, 'wb') as f:\n",
        "        df_val.to_csv(f)\n",
        "else:\n",
        "    # Gists of the already processed datasets\n",
        "    train_url = 'https://gist.githubusercontent.com/jihan-yin/43f19a86d35bf22fa3551d2806e478ec/raw/91416c09f09d3fca974f81d1f766dd4cadb29789/scienceqa_train.csv'\n",
        "    val_url = 'https://gist.githubusercontent.com/jihan-yin/43f19a86d35bf22fa3551d2806e478ec/raw/91416c09f09d3fca974f81d1f766dd4cadb29789/scienceqa_val.csv'\n",
        "\n",
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2fc8d76",
      "metadata": {
        "id": "e2fc8d76"
      },
      "source": [
        "# Fine-tune\n",
        "Now, we can fine-tune the model using LLM Engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4905d447",
      "metadata": {
        "id": "4905d447"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_url' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\namit\\OneDrive - Trinity College Dublin\\sources\\openfabric-ai-software-engineer\\openfabric-ai-software-engineer\\training\\download_a_finetuned_model.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mSCALE_API_KEY\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest_e486e3e02f2e4940816ad04c939bc66f\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllmengine\u001b[39;00m \u001b[39mimport\u001b[39;00m FineTune\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m response \u001b[39m=\u001b[39m FineTune\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mllama-2-7b\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     training_file\u001b[39m=\u001b[39mtrain_url,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     validation_file\u001b[39m=\u001b[39mval_url,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     hyperparameters\u001b[39m=\u001b[39m{\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m2e-4\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     },\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     suffix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscience-qa-llama\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/namit/OneDrive%20-%20Trinity%20College%20Dublin/sources/openfabric-ai-software-engineer/openfabric-ai-software-engineer/training/download_a_finetuned_model.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m run_id \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mid\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_url' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['SCALE_API_KEY'] = 'test_e486e3e02f2e4940816ad04c939bc66f'\n",
        "\n",
        "from llmengine import FineTune\n",
        "train_url = './train.csv'\n",
        "validate = './val.csv'\n",
        "response = FineTune.create(\n",
        "    model=\"llama-2-7b\",\n",
        "    training_file=train_url,\n",
        "    validation_file=val_url,\n",
        "    hyperparameters={\n",
        "        'lr':2e-4,\n",
        "    },\n",
        "    suffix='science-qa-llama'\n",
        ")\n",
        "run_id = response.id"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55074457",
      "metadata": {
        "id": "55074457"
      },
      "source": [
        "We can sleep until the job completes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "840938dd",
      "metadata": {
        "id": "840938dd"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "while True:\n",
        "    job_status = FineTune.get(run_id).status\n",
        "    print(job_status)\n",
        "    if job_status == 'SUCCESS':\n",
        "        break\n",
        "    time.sleep(60)\n",
        "\n",
        "fine_tuned_model = FineTune.get(run_id).fine_tuned_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31278c6d",
      "metadata": {
        "id": "31278c6d"
      },
      "source": [
        "# Downloading our Finetuned model \n",
        "Let's download the weights for the new fine-tuned model using LLM Engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f2f3f43",
      "metadata": {
        "id": "9f2f3f43"
      },
      "outputs": [],
      "source": [
        "from llmengine import Model\n",
        "\n",
        "response = Model.download(FineTune.get(run_id).fine_tune_model, download_format=\"hugging_face\")\n",
        "print(response.urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9cbdf3",
      "metadata": {},
      "source": [
        "We now have a dictionary of filenames and urls that point to the file(s) where our finetuned model lives. We can download the associated finetuned model either synchronously or asynchronously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc363e48",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "def download_files(url_dict, directory):\n",
        "    \"\"\"\n",
        "    Download files from given URLs to specified directory.\n",
        "    \n",
        "    Parameters:\n",
        "    - url_dict: Dictionary of {file_name: url} pairs.\n",
        "    - directory: Directory to save the files.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    \n",
        "    for file_name, url in url_dict.items():\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "        file_path = os.path.join(directory, file_name)\n",
        "        \n",
        "        with open(file_path, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                file.write(chunk)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "000e1633",
      "metadata": {},
      "outputs": [],
      "source": [
        "output_directory = \"YOUR_MODEL_DIR\"\n",
        "download_files(response.urls, output_directory) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e87233",
      "metadata": {},
      "source": [
        "Lastly, we can upload our downloaded model to the huggingface hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c8ee18",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install huggingface-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "328efd19",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import Repository\n",
        "\n",
        "HF_USERNAME = \"YOUR_HUGGINGFACE_USERNAME\"\n",
        "HF_TOKEN = \"YOUR_HUGGINGFACE_TOKEN\"\n",
        "\n",
        "def upload_to_huggingface(directory, model_name):\n",
        "    \"\"\"\n",
        "    Upload files from a directory to the Hugging Face Hub as a new model.\n",
        "\n",
        "    Parameters:\n",
        "    - directory: Directory containing the files to be uploaded.\n",
        "    - model_name: Name of the new model.\n",
        "    - token: Your Hugging Face authentication token.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create a repository with the given name\n",
        "    repo = Repository(directory, clone_from=f\"{HF_USERNAME}/{model_name}\", use_auth_token=HF_TOKEN)\n",
        "    \n",
        "    # Commit and push files\n",
        "    repo.push_to_hub()\n",
        "\n",
        "model_name = \"my-new-model\"\n",
        "    \n",
        "upload_to_huggingface(output_directory, model_name, HF_TOKEN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "openfabric-test-UGfvBDS8-py3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
